# Trabajo Pr√°ctico Final - Clasificaci√≥n de Im√°genes CIFAR-10

**Visi√≥n Computacional Basada en Redes Neuronales Artificiales**  
**Grupo 3**

## üë• Integrantes

- Joaqu√≠n Sebasti√°n Tschopp
- Santiago Bezchinsky

---

## üìã √çndice

1. [Descripci√≥n del Proyecto](#-descripci√≥n-del-proyecto)
2. [Dataset CIFAR-10](#-dataset-cifar-10)
3. [Arquitectura del Pipeline](#-arquitectura-del-pipeline)
4. [Modelos Implementados](#-modelos-implementados)
5. [C√≥mo Usar el Notebook](#-c√≥mo-usar-el-notebook)
6. [Estructura del Proyecto](#-estructura-del-proyecto)
7. [Requisitos](#-requisitos)

---

## üéØ Descripci√≥n del Proyecto

Este proyecto implementa un **pipeline completo de Deep Learning** para clasificaci√≥n de im√°genes usando el dataset CIFAR-10. La soluci√≥n est√° dise√±ada con **arquitectura orientada a objetos** que permite:

‚úÖ **Entrenar m√∫ltiples arquitecturas CNN** de forma intercambiable  
‚úÖ **Validaci√≥n autom√°tica** con early stopping  
‚úÖ **Evaluaci√≥n en datasets externos** (CIFAR-10.1)  
‚úÖ **Visualizaciones profesionales** de resultados  
‚úÖ **Detecci√≥n autom√°tica de hardware** (CUDA/MPS/CPU)  

---

## üìä Dataset CIFAR-10

### Descripci√≥n General

**CIFAR-10** (Canadian Institute For Advanced Research) es un dataset de referencia en Computer Vision que contiene **60,000 im√°genes a color de 32√ó32 p√≠xeles**, divididas en **10 clases mutuamente excluyentes**.

### Composici√≥n del Dataset

| Clase | ID | Nombre | Descripci√≥n | Ejemplos |
|-------|-----|--------|-------------|----------|
| 0 | ‚úàÔ∏è | **Airplane** | Aviones comerciales, jets, avionetas | Boeing 747, Cessna, F-16 |
| 1 | üöó | **Automobile** | Sedanes, SUVs, autos deportivos | Toyota, Ford, Ferrari |
| 2 | üê¶ | **Bird** | P√°jaros de diferentes especies | √Åguila, colibr√≠, gorri√≥n |
| 3 | üê± | **Cat** | Gatos dom√©sticos | Persa, siam√©s, com√∫n |
| 4 | ü¶å | **Deer** | Venados, ciervos | Ciervo de cola blanca |
| 5 | üêï | **Dog** | Perros de diferentes razas | Labrador, bulldog, husky |
| 6 | üê∏ | **Frog** | Ranas y sapos | Rana arb√≥rea, sapo com√∫n |
| 7 | üê¥ | **Horse** | Caballos | Pura sangre, mustang |
| 8 | üö¢ | **Ship** | Barcos, buques, veleros | Crucero, yate, carguero |
| 9 | üöö | **Truck** | Camiones, camionetas | Pickup, cami√≥n de carga |

### Distribuci√≥n de Datos

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  CIFAR-10 Dataset Split                     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  üì¶ Training:   50,000 im√°genes (83.3%)     ‚îÇ
‚îÇ  üìä Validation: 10,000 im√°genes (16.7%)     ‚îÇ
‚îÇ  üß™ Test:        2,021 im√°genes (CIFAR-10.1)‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Caracter√≠sticas t√©cnicas:**
- **Resoluci√≥n**: 32√ó32 p√≠xeles (baja resoluci√≥n intencional)
- **Canales**: 3 (RGB)
- **Balanceo**: Perfectamente balanceado (6,000 im√°genes por clase en training)
- **Normalizaci√≥n**: Media `[0.491, 0.482, 0.447]`, Std `[0.247, 0.243, 0.262]`

### CIFAR-10.1 (Test Set Independiente)

Utilizamos **CIFAR-10.1** como conjunto de test final. Este dataset fue creado en **2019** por investigadores de UC Berkeley para:

- Evaluar la **verdadera generalizaci√≥n** de modelos
- Detectar **overfitting al dataset original**
- Contiene im√°genes **completamente nuevas** con la misma metodolog√≠a
- **Gap t√≠pico**: 4-10% menos accuracy que CIFAR-10 test set

---

## üèóÔ∏è Arquitectura del Pipeline

### Clase `TrainingPipeline`

El proyecto est√° construido sobre una **clase orientada a objetos** que encapsula todo el flujo de trabajo:

```python
TrainingPipeline
‚îú‚îÄ‚îÄ __init__()              # Inicializaci√≥n + detecci√≥n de hardware
‚îú‚îÄ‚îÄ _detect_device()        # CUDA > MPS > CPU (autom√°tico)
‚îú‚îÄ‚îÄ _train_epoch()          # Entrenamiento de una √©poca
‚îú‚îÄ‚îÄ _validate_epoch()       # Validaci√≥n de una √©poca
‚îú‚îÄ‚îÄ train()                 # Loop completo con early stopping
‚îú‚îÄ‚îÄ save_checkpoint()       # Guardar modelo autom√°ticamente
‚îú‚îÄ‚îÄ load_checkpoint()       # Cargar modelo guardado
‚îú‚îÄ‚îÄ resume_training()       # Reanudar entrenamiento interrumpido
‚îú‚îÄ‚îÄ evaluate()              # Evaluaci√≥n completa con m√©tricas
‚îú‚îÄ‚îÄ plot_training_curves()  # Visualizaci√≥n de curvas de aprendizaje
‚îú‚îÄ‚îÄ plot_confusion_matrix() # Matriz de confusi√≥n
‚îî‚îÄ‚îÄ plot_examples()         # Ejemplos visuales de predicciones
```

### Diagrama de Flujo

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Cargar Datos   ‚îÇ
‚îÇ   (CIFAR-10)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Crear Modelo    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  BaseModel       ‚îÇ
‚îÇ                 ‚îÇ      ‚îÇ  SimpleCNN       ‚îÇ
‚îÇ                 ‚îÇ      ‚îÇ  ImprovedCNN ‚≠ê  ‚îÇ
‚îÇ                 ‚îÇ      ‚îÇ  ResNetCIFAR     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Inicializar Pipeline       ‚îÇ
‚îÇ  - Detecta hardware (GPU)   ‚îÇ
‚îÇ  - Configura optimizador    ‚îÇ
‚îÇ  - Inicializa m√©tricas      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     Loop de Training        ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ  √âpoca 1..N         ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ Train          ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ Validate       ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ Checkpoint     ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ Early Stop?    ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Visualizar Resultados      ‚îÇ
‚îÇ  - Curvas de loss/accuracy  ‚îÇ
‚îÇ  - An√°lisis de overfitting  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Evaluar en Test Set        ‚îÇ
‚îÇ  - CIFAR-10.1 (2,021 imgs)  ‚îÇ
‚îÇ  - Matriz de confusi√≥n      ‚îÇ
‚îÇ  - Accuracy por clase       ‚îÇ
‚îÇ  - Ejemplos visuales        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Caracter√≠sticas Principales

#### üñ•Ô∏è Detecci√≥n Autom√°tica de Hardware

```python
def _detect_device(self):
    if torch.cuda.is_available():
        return torch.device('cuda')  # NVIDIA GPU
    elif torch.backends.mps.is_available():
        return torch.device('mps')   # Apple Silicon
    else:
        return torch.device('cpu')   # CPU fallback
```

**Beneficios:**
- No requiere configuraci√≥n manual
- Aprovecha GPU autom√°ticamente
- Funciona en cualquier plataforma

#### üîÑ Sistema de Checkpoints Robusto

```python
models/
‚îú‚îÄ‚îÄ best_model.pth              # Mejor accuracy de validaci√≥n
‚îú‚îÄ‚îÄ last_checkpoint.pth         # Checkpoint cada 5 √©pocas
‚îî‚îÄ‚îÄ interrupted_checkpoint.pth  # Si se interrumpe (Ctrl+C)
```

**Caracter√≠sticas:**
- ‚úÖ Guardado autom√°tico cada 5 √©pocas
- ‚úÖ Mejor modelo siempre guardado
- ‚úÖ Recuperaci√≥n ante interrupciones
- ‚úÖ M√©todo `resume_training()` para continuar

#### ‚èπÔ∏è Early Stopping

- Monitorea accuracy de validaci√≥n
- Se detiene si no hay mejora en N √©pocas
- Evita overfitting
- Ahorra tiempo de entrenamiento

---

## üß† Modelos Implementados

### Comparaci√≥n R√°pida

| Modelo | Par√°metros | Accuracy Esperado | Velocidad | Mejor Para |
|--------|------------|-------------------|-----------|------------|
| **BaseModel** | 1.6M | ~50% | 1.0x | Baseline |
| **SimpleCNN** | 122K | 65-70% | 1.2x | Prototipado r√°pido |
| **ImprovedCNN** ‚≠ê | 340K | **75-80%** | 1.5x | **Producci√≥n** |
| **ResNetCIFAR** | 470K | 80-85% | 2.0x | M√°ximo rendimiento |

---

### 1Ô∏è‚É£ BaseModel (Baseline)

**Arquitectura:** Fully Connected de 2 capas

```python
nn.Sequential(
    nn.Flatten(),           # 3√ó32√ó32 = 3072 features
    nn.Linear(3072, 512),
    nn.Tanh(),
    nn.Linear(512, 10)
)
```

**Caracter√≠sticas:**
- ‚ùå No usa convoluciones
- üìä Par√°metros: ~1.6M
- üéØ Accuracy: ~50%
- üí° Uso: Baseline para comparaci√≥n

---

### 2Ô∏è‚É£ SimpleCNN

**Arquitectura:** CNN b√°sica con 3 bloques convolucionales

```
Input (3√ó32√ó32)
    ‚Üì
[Conv 3‚Üí32, 3√ó3] ‚Üí ReLU ‚Üí MaxPool ‚Üí (32√ó16√ó16)
[Conv 32‚Üí64, 3√ó3] ‚Üí ReLU ‚Üí MaxPool ‚Üí (64√ó8√ó8)
[Conv 64‚Üí128, 3√ó3] ‚Üí ReLU ‚Üí MaxPool ‚Üí (128√ó4√ó4)
    ‚Üì
Flatten ‚Üí FC(2048‚Üí256) ‚Üí Dropout(0.5) ‚Üí FC(256‚Üí10)
```

**Caracter√≠sticas:**
- ‚úÖ 3 capas convolucionales
- ‚úÖ Dropout para regularizaci√≥n
- üìä Par√°metros: ~122K
- üéØ Accuracy: 65-70%
- ‚ö° R√°pida de entrenar

---

### 3Ô∏è‚É£ ImprovedCNN ‚≠ê **RECOMENDADA**

**Arquitectura:** CNN profunda con Batch Normalization

```
Input (3√ó32√ó32)
    ‚Üì
[Conv 3‚Üí64] ‚Üí BatchNorm ‚Üí ReLU ‚Üí (64√ó32√ó32)
[Conv 64‚Üí128] ‚Üí BatchNorm ‚Üí ReLU ‚Üí MaxPool ‚Üí Dropout ‚Üí (128√ó16√ó16)
[Conv 128‚Üí256] ‚Üí BatchNorm ‚Üí ReLU ‚Üí (256√ó16√ó16)
[Conv 256‚Üí256] ‚Üí BatchNorm ‚Üí ReLU ‚Üí MaxPool ‚Üí Dropout ‚Üí (256√ó8√ó8)
[Conv 256‚Üí512] ‚Üí BatchNorm ‚Üí ReLU ‚Üí MaxPool ‚Üí Dropout ‚Üí (512√ó4√ó4)
    ‚Üì
Flatten ‚Üí FC(8192‚Üí512) ‚Üí BatchNorm ‚Üí Dropout ‚Üí FC(512‚Üí10)
```

**Caracter√≠sticas:**
- ‚úÖ 5 bloques convolucionales
- ‚úÖ Batch Normalization (acelera convergencia)
- ‚úÖ Dropout estrat√©gico (previene overfitting)
- üìä Par√°metros: ~340K
- üéØ Accuracy: **75-80%**
- üèÜ **Mejor balance complejidad/rendimiento**

---

### 4Ô∏è‚É£ ResNetCIFAR

**Arquitectura:** ResNet adaptado con skip connections

```
Input (3√ó32√ó32)
    ‚Üì
[Conv 3‚Üí64, 3√ó3] ‚Üí BatchNorm ‚Üí ReLU
    ‚Üì
ResidualBlock √ó2 (64‚Üí64) ‚Üí (64√ó32√ó32)
ResidualBlock √ó2 (64‚Üí128, stride=2) ‚Üí (128√ó16√ó16)
ResidualBlock √ó2 (128‚Üí256, stride=2) ‚Üí (256√ó8√ó8)
    ‚Üì
GlobalAvgPool ‚Üí FC(256‚Üí10)
```

**Bloque Residual:**
```
x ‚Üí [Conv ‚Üí BN ‚Üí ReLU ‚Üí Conv ‚Üí BN] ‚Üí (+) ‚Üí ReLU
‚Üì_________shortcut (identity)_______‚Üë
```

**Caracter√≠sticas:**
- ‚úÖ Skip connections (combaten vanishing gradient)
- ‚úÖ Global Average Pooling
- üìä Par√°metros: ~470K
- üéØ Accuracy: 80-85%
- üöÄ Arquitectura state-of-the-art

---

## üöÄ C√≥mo Usar el Notebook

### Gu√≠a Paso a Paso

#### **Paso 1: Ejecutar Setup (Celdas 1-10)**

```python
# Importaciones autom√°ticas
# Descarga de CIFAR-10
# C√°lculo de media y std para normalizaci√≥n
```

**Output esperado:**
```
‚úì datasets/Grupo_3/cifar10.1_v4_data.npy ya existe
Mean: [0.491, 0.482, 0.447]
Std:  [0.247, 0.243, 0.262]
```

---

#### **Paso 2: Comparar Modelos (Opcional - Celda 17)**

```python
compare_models()
```

**Output:**
```
======================================================================
COMPARACI√ìN DE ARQUITECTURAS
======================================================================

BaseModel (actual)
  Par√°metros totales: 1,578,506
  Tama√±o estimado: 6.02 MB

SimpleCNN
  Par√°metros totales: 122,282
  Tama√±o estimado: 0.47 MB

ImprovedCNN (recomendada)
  Par√°metros totales: 340,042
  Tama√±o estimado: 1.30 MB

ResNetCIFAR
  Par√°metros totales: 469,194
  Tama√±o estimado: 1.79 MB
======================================================================
```

---

#### **Paso 3: Elegir Arquitectura (Celda 22)**

```python
# Opci√≥n 1: Baseline (~50% accuracy)
model = BaseModel()

# Opci√≥n 2: CNN simple (65-70% accuracy)
model = SimpleCNN()

# Opci√≥n 3: CNN mejorada (75-80% accuracy) ‚≠ê RECOMENDADA
model = ImprovedCNN()

# Opci√≥n 4: ResNet (80-85% accuracy)
model = ResNetCIFAR()
```

---

#### **Paso 4: Configurar Hiperpar√°metros (Celda 21)**

```python
config = {
    'lr': 0.001,           # Learning rate
    'epochs': 50,          # N√∫mero m√°ximo de √©pocas
    'batch_size': 64,      # Tama√±o de batch
    'patience': 10,        # Early stopping patience
    'momentum': 0.9,       # Momentum para SGD
    'checkpoint_dir': 'models/'
}
```

**Tips de configuraci√≥n:**
- ‚¨ÜÔ∏è `lr` m√°s alto ‚Üí Converge m√°s r√°pido (pero puede ser inestable)
- ‚¨áÔ∏è `batch_size` m√°s peque√±o ‚Üí Menos memoria GPU
- ‚¨ÜÔ∏è `patience` m√°s alto ‚Üí M√°s tiempo antes de detener

---

#### **Paso 5: Entrenar (Celda 23)**

```python
pipeline = TrainingPipeline(model, config)
pipeline.train(train_dataloader, validation_dataloader)
```

**Output en tiempo real:**
```
======================================================================
ENTRENAMIENTO DEL MODELO
======================================================================
√âpocas: 50
Batch size: 64
Learning rate: 0.001
Device: mps                    ‚Üê Detecta autom√°ticamente
======================================================================

Epoch 01 | Train Loss: 1.8265 | Val Loss: 1.7435 | Val Acc: 39.67% ‚úì MEJOR
Epoch 02 | Train Loss: 1.6981 | Val Loss: 1.6797 | Val Acc: 42.75% ‚úì MEJOR
...
Epoch 25 | Train Loss: 0.8768 | Val Loss: 1.5257 | Val Acc: 49.83% ‚úì MEJOR
  ‚Üí Checkpoint guardado
...

! Early stopping en √©poca 35
  Mejor accuracy: 49.83% (√©poca 25)
======================================================================
```

---

#### **Paso 6: Visualizar Curvas (Celda 25)**

```python
pipeline.plot_training_curves()
```

**Genera 3 gr√°ficos:**
1. üìâ **Loss**: Training vs Validation
2. üìà **Accuracy**: Evoluci√≥n por √©poca
3. ‚ö†Ô∏è **Overfitting**: Gap entre train y val

---

#### **Paso 7: Evaluar en Test (Celdas 27-28)**

```python
# Evaluaci√≥n
results = pipeline.evaluate(test_dataloader, "CIFAR-10.1")

# Visualizaciones
pipeline.plot_confusion_matrix(results['predictions'], 
                               results['labels'], 
                               class_names)

pipeline.plot_examples(images, 
                      results['predictions'], 
                      results['labels'],
                      class_names, mean, std)
```

**Output:**
```
======================================================================
EVALUACI√ìN EN CIFAR-10.1
======================================================================
Accuracy en CIFAR-10.1: 36.81%
   Correctas: 744/2021

ACCURACY POR CLASE
======================================================================
  airplane    : 32.69%  ( 208 samples)
  automobile  : 38.21%  ( 212 samples)
  ...
======================================================================
```

---

#### **Paso 8: Reanudar si se Interrumpi√≥ (Celda 24)**

```python
pipeline.resume_training('interrupted_checkpoint.pth',
                        train_dataloader,
                        validation_dataloader)
```

---

## üìÅ Estructura del Proyecto

```
TP-FINAL/
‚îú‚îÄ‚îÄ VCBRNA-grupo-3.ipynb           # üìì Notebook principal
‚îú‚îÄ‚îÄ README.md                       # üìÑ Este archivo
‚îú‚îÄ‚îÄ Trabajo Pr√°ctico Especial.pdf  # üìã Consigna
‚îÇ
‚îú‚îÄ‚îÄ datasets/                       # üíæ Datos (en .gitignore)
‚îÇ   ‚îî‚îÄ‚îÄ Grupo_3/
‚îÇ       ‚îú‚îÄ‚îÄ cifar-10-batches-py/   # CIFAR-10 original
‚îÇ       ‚îú‚îÄ‚îÄ cifar10.1_v4_data.npy  # Test set CIFAR-10.1
‚îÇ       ‚îî‚îÄ‚îÄ cifar10.1_v4_labels.npy
‚îÇ
‚îî‚îÄ‚îÄ models/                         # ü§ñ Modelos guardados
    ‚îú‚îÄ‚îÄ best_model.pth              # Mejor accuracy
    ‚îú‚îÄ‚îÄ last_checkpoint.pth         # √öltimo checkpoint
    ‚îî‚îÄ‚îÄ interrupted_checkpoint.pth  # Si hubo Ctrl+C
```

---

## üì¶ Requisitos

### Librer√≠as

```python
torch >= 2.0.0          # Framework de Deep Learning
torchvision >= 0.15.0   # Datasets y transformaciones
numpy >= 1.24.0         # Manipulaci√≥n de arrays
matplotlib >= 3.7.0     # Visualizaci√≥n
seaborn >= 0.12.0       # Gr√°ficos estad√≠sticos
scikit-learn >= 1.3.0   # M√©tricas (confusion matrix)
```

### Instalaci√≥n

```bash
# Activar entorno virtual
source .venv/bin/activate  # Linux/Mac

# Instalar dependencias
pip install torch torchvision numpy matplotlib seaborn scikit-learn
```

### Hardware Recomendado

| Hardware | RAM | Tiempo/√âpoca | Notas |
|----------|-----|--------------|-------|
| **CPU** | 8GB+ | ~5-10 min | Funcional pero lento |
| **Apple Silicon (M1/M2/M3)** | 8GB+ | ~1-2 min | ‚≠ê Excelente balance |
| **NVIDIA GPU (CUDA)** | 4GB VRAM+ | ~30-60 seg | ‚≠ê M√°s r√°pido |

---

## ‚ú® Caracter√≠sticas Destacadas

### üéØ Pipeline Orientado a Objetos
- **C√≥digo limpio** y organizado
- **Reutilizable** en otros proyectos
- **Extensible** (f√°cil agregar modelos)
- **Testeable** (m√©todos independientes)

### üñ•Ô∏è Multi-plataforma
```python
Device detectado: mps    # Mac con Apple Silicon
Device detectado: cuda   # PC con NVIDIA GPU
Device detectado: cpu    # Cualquier m√°quina
```

### üìä Visualizaciones Profesionales
- Curvas de loss/accuracy con seaborn
- Matriz de confusi√≥n interactiva
- Ejemplos visuales de predicciones
- An√°lisis autom√°tico de overfitting

### üõ°Ô∏è Prevenci√≥n de Overfitting
- **Early stopping** autom√°tico
- **Dropout** (0.5) en capas FC
- **Batch Normalization** para estabilidad
- **Data augmentation** ready

---

## üìù Quick Start (3 L√≠neas)

```python
# 1. Crear y entrenar
pipeline = TrainingPipeline(ImprovedCNN(), config)
pipeline.train(train_dataloader, validation_dataloader)

# 2. Evaluar
results = pipeline.evaluate(test_dataloader, "CIFAR-10.1")
```

**¬°Listo! üéâ**

---

## üôè Referencias

- **CIFAR-10**: Krizhevsky, A. (2009). Learning Multiple Layers of Features from Tiny Images.
- **CIFAR-10.1**: Recht, B., et al. (2019). Do ImageNet Classifiers Generalize to ImageNet? ICML.
- **ResNet**: He, K., et al. (2016). Deep Residual Learning for Image Recognition. CVPR.
- **Batch Normalization**: Ioffe, S., & Szegedy, C. (2015). Batch Normalization. ICML.

---

**√öltima actualizaci√≥n**: Octubre 2025  
**Versi√≥n**: 1.0  
**Notebook**: `VCBRNA-grupo-3.ipynb`
